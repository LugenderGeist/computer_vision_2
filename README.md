# computer_vision_2
## Введение
Целью даной работы является изучение методов, определяющих ключевые точки на изображениях с целью определения траектории движения камеры. Для этого были взяты два изображения со сдвигом камеры, определены ключевые точки с помощью метода SIFT, самые значимые из были были отфильтрованы по критериям size и response. Точки были сопоставлены с помощью библиотеки FLANN, после чего была построена траектория движения камеры. 
В работе будут использоваться две фотографии со сдвигом камеры:  
![крыса](https://github.com/LugenderGeist/computer_vision_2/blob/main/rat.png)

## Перевод изображений в Grayscale
![grayscale](https://github.com/LugenderGeist/computer_vision_2/blob/main/grayscale.png)  

## Выравнивание яркости  
Дескриптор ключевой точки (keypoint descriptor) — это числовое представление окрестности ключевой точки, которое описывает её уникальные характеристики. Дескриптор позволяет сравнивать ключевые точки между изображениями и определять их схожесть, даже если изображения подверглись изменениям.  
Разная яркость изображений может повлиять на формирование дескриптора, а при сопоставлении изображений многие алгоритмы опираются на сравнение дескрипторов ключевых точек. Если дескрипторы различаются из-за различий яркости - это может привести к ошибочным соответствиям или недостатку хороших совпадений. Поэтому выберем метод и выровняем яркость изображений.   
Для выравнивания яркости будем использовать метод линейной трансформации яркости и выровняем яркость второго изображения относительно первого.  
Этот метод изменит яркость и контраст второго изображения так, чтобы его среднее значение (mean) и стандартное отклонение (std) стали равны соответствующим значениям первого изображения.
- Для каждого изображения вычисляются среднее значение (mean) и стандартное отклонение (std).
- Вычисляется коэффициент масштабирования α=std1/std2, который регулирует контрастность.
- Вычисляется смещение β=mean1-αmean2, которое регулирует яркость.
- Каждый пиксель второго изображения преобразуется по формуле: new_pixel=α(pixel−mean2)+mean1
- После преобразования значения пикселей могут выходить за диапазон [0, 255], поэтому их необходимо нормализовать.  
 ![brightness](https://github.com/LugenderGeist/computer_vision_2/blob/main/brightness.png)
 ![histogram](https://github.com/LugenderGeist/computer_vision_2/blob/main/histogramms.png) 
По гистограмме сложно сказать, что изображения стали ближе друг к другу по яркости. Однако, работа уже проделана, поэтому проверим, действительно ли такая обработка изображения в данном случае даст какой-то значимый результат при поиске общих ключевых точек.

## Применение метода SIFT  
SIFT (Scale-Invariant Feature Transform) — алгоритм обнаружения ключевых точек и вычисления их дескрипторов, работающий на основе генерации пирамиды масштабов: исходное изображение фильтруется с помощью гауссовых ядер с разными значениями параметра σ (стандартного отклонения). Так создается пирамида масштабов, где каждый слой представляет собой последовательность изображений, уменьшенных в два раза относительно предыдущей октавы.  
В каждой октаве строится несколько уровней, называемых пространством масштабов (S).  
Для каждого уровня масштаба вычисляется функция (Difference of Gaussians, DoG): D(x,y,σ)=G(x,y,kσ)−G(x,y,σ), экстремумы которой считаются потенциальными ключевыми точками.  
Для каждой ключевой точки вычисляются градиенты интенсивности в её окрестности, чтобы в дальнейшем можно было определить эту же точку при вращении.  
Далее необходимо вычислить дискрипторы ключевых точек: для окретсности каждой ключевой точки создается уникальное числовое представление:  
- Определяется область вокруг ключевой точки, размер которой зависит от её масштаба (σ).
- Область делится на сетку блоков (обычно 4×4).
- Для каждого пикселя в области вычисляются магнитуда и направление градиента.
- Для каждого блока строится гистограмма направлений градиентов (обычно 8–16 бинов).
- Все гистограммы объединяются в один вектор фиксированной длины. (Например, для SIFT длина дескриптора составляет 4×4×8=128 элементов.)
- Дескриптор нормируется, чтобы сделать его устойчивым к изменениям освещения и контраста.
![SIFT](https://github.com/LugenderGeist/computer_vision_2/blob/main/keypoints.png)
На данном этапе можно увидеть, что на обработанном изображении ключевых точек больше и размер дескриптора больше. Количество ключевых точек, потенциально даст большую вероятность того, что найдется больше соответствий с первым изображением.

## Фильтрация ключевых точек
Полученные точки отфильтруем по критериям:
- response - разница между тем, какое значение по гауссовому распределению имела точка ранее, и какое значение она имеет на данном слое обработки. По сути, это то, насколько важной точка осталась при переходе с одного слоя на другой.
- size - размер области, которая описывает ключевую точку, определяющаяся слоем, на котором точка была обнаружена.  
![filtered](https://github.com/LugenderGeist/computer_vision_2/blob/main/filtered_keypoints.png)  
После фильтрации количество ключевых точек на обработанном изображении все еще больше, что говорит о том, что на нем больше значимых точек, которые остались после фильтрации.

## Сопоставление точек
FLANN (Fast Library for Approximate Nearest Neighbors) — это библиотека для быстрого поиска приближенных ближайших соседей в многомерных пространствах. FLANN решает задачу поиска ближайших соседей, которая заключается в нахождении точек из набора данных, наиболее близких к заданной точке. В контексте компьютерного зрения FLANN используется для сопоставления дескрипторов ключевых точек между изображениями.  
Сначала сопоставим точки между первым изображением и обработанным:  
![keypoints_1](https://github.com/LugenderGeist/computer_vision_2/blob/main/keypoints_1.png)  
Теперь сопоставим первое изображение с необработанным:  
![keypoints_2](https://github.com/LugenderGeist/computer_vision_2/blob/main/keypoints_2.png)  
После сопоставления первого изображения с обработанным и необработанным получим разницу всего в одну ключевую точку. При изменении значений size и response в большую и меньшую стороны - количество ключевых точек все равно не отличается больше чем на 3. Из этого можно сделать вывод, что в данной ситуации, при незначительном отклонении камеры между двумя изображениями и фотографиями, отличающимися незначительно по яркости - не обязательно регулировать яркость изображения, так как она, видимо, находится в допустимом диапазоне.  

## Построение траектории движения камеры
По полученным ключевым точкчам построим траекторию движения камеры. Для этого необходимо определить несколько величин.
K — внутренняя матрица камеры [3x3]. Зададим ее как примерную матрицу для камеры с разрешением 1280х720p.  
Фундаментальная матрица F — это матрица [3×3], которая также связывает соответствующие точки на двух изображениях, но в пиксельном пространстве. Она вычисляется с использованием алгоритмов, таких как RANSAC, который отсеивает шумные соответствия.  
Эссенциальная матрица E — это матрица [3×3], которая связывает соответствующие точки на двух изображениях, сделанных одной камерой с разных позиций. Она содержит информацию о положении и ориентации камеры между двумя кадрами. Математически, если точка x1 на первом изображении соответствует точке x2 на втором изображении, то их координаты удовлетворяют следующему уравнению:  
x2^T⋅E⋅x1=0  
Здесь x1 и x2 — нормализованные координаты точек (в однородных координатах). E — эссенциальная матрица.  
Из эссенциальной матрицы можно получить матрицу поворота R и вектор перемещения t, которые описывают движение камеры между двумя кадрами.
![trajectory](https://github.com/LugenderGeist/computer_vision_2/blob/main/trajectory.png)  

По результатам построения траектории видно, как именно была сдвинута камера. Были изучены метод SIFT, изучены критерии определения важности ключевых точек, библиотека FLANN. Был изучен принцип построения траектории движения камеры.
